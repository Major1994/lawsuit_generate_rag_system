# main.py

import json
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from peft import PeftModel
from json_output import parser  # å‡è®¾ parser æ˜¯ StructuredOutputParser
import torch
from tqdm import tqdm
import pickle
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.output_parsers import OutputFixingParser
from langchain_openai import ChatOpenAI
import random
import os
import dashscope

# ================== é…ç½® ==================
DASHSCOPE_API_KEY = "sk-af51f271a37748439c658f3882f4d969"
EMBEDDING_MODEL_PATH = "/root/autodl-tmp/Qwen3-Embedding-8B"
VECTOR_DB_PATH = "law_db_native"  # å¯¹åº”ä¹‹å‰ä¿å­˜çš„ native FAISS
CASE_NUM = 3

# ================== åˆå§‹åŒ–å¤§æ¨¡å‹ ==================
dashscope.api_key = DASHSCOPE_API_KEY

def think(prompt, stream=False):
    """è°ƒç”¨ Qwen3 ç”Ÿæˆå¸æ³•è§£é‡Š"""
    messages = [
        {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„æ³•å¾‹é¡¾é—®ï¼Œæ“…é•¿æ’°å†™æ­£å¼ã€ä¸¥è°¨çš„å¸æ³•è§£é‡Šã€‚'},
        {'role': 'user', 'content': prompt}
    ]
    response = dashscope.Generation.call(
        model="qwen3-30b-a3b",
        messages=messages,
        result_format='message',
        stream=stream,
        enable_thinking=False
    )
    if response.status_code == 200:
        return response.output.choices[0].message.content
    else:
        raise Exception(f"API è°ƒç”¨å¤±è´¥: {response.message}")

# ================== åŠ è½½å‘é‡æ•°æ®åº“ï¼ˆæ¨èæ–¹å¼ï¼‰==================
def load_vector_db():
    print("åŠ è½½åµŒå…¥æ¨¡å‹...")
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_PATH,
        model_kwargs={"device": "cuda"},
        encode_kwargs={"normalize_embeddings": True}  # æ³¨æ„ï¼šå†…ç§¯ç›¸ä¼¼åº¦éœ€å½’ä¸€åŒ–
    )
    print("åŠ è½½å‘é‡æ•°æ®åº“...")
    db = FAISS.load_local(
        VECTOR_DB_PATH,
        embedding_model,
        allow_dangerous_deserialization=True  # å…è®¸åŠ è½½ pickle
    )
    return db

db = load_vector_db()

# ================== OutputFixingParser åˆå§‹åŒ– ==================
try:
    from langchain_core.output_parsers import OutputFixingParser
except ImportError:
    from langchain.output_parsers import OutputFixingParser

llm_for_fix = ChatOpenAI(
    model="qwen2.5-32b-instruct",
    base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',
    api_key=DASHSCOPE_API_KEY,
    temperature=0.3
)
fix_parser = OutputFixingParser.from_llm(parser=parser, llm=llm_for_fix)

# ================== ç½ªåé¢„æµ‹æ¨¡å—ï¼ˆå‡è®¾ predict_accusation.py æä¾›ï¼‰==================
# æ³¨æ„ï¼šç¡®ä¿ predict_accusation.py ä¸­æœ‰ predict_accusation(text) å‡½æ•°
from predict_accusation import predict_accusation

# ================== è¾…åŠ©å‡½æ•° ==================
def accusation_json2str(data):
    """å°†åˆ¤å†³ JSON è½¬ä¸ºè‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²"""
    result = "åˆ¤å†³ç»“æœï¼š"
    result += "ç½ªåï¼š" + "ã€".join(data.get("ç½ªå", ["æœªçŸ¥"])) + "ï¼›"
    result += "ç½šé‡‘ï¼š" + str(data.get("ç½šé‡‘", 0)) + "å…ƒï¼›"
    result += "ç½ªçŠ¯ï¼š" + "ã€".join(data.get("çŠ¯ç½ªå«Œç–‘äºº", ["æœªçŸ¥"])) + "ï¼›"
    if data.get("æ˜¯å¦æ­»åˆ‘", False):
        result += "åˆ‘æœŸï¼šæ­»åˆ‘"
    elif data.get("æ˜¯å¦æ— æœŸ", False):
        result += "åˆ‘æœŸï¼šæ— æœŸå¾’åˆ‘"
    else:
        result += f"åˆ‘æœŸï¼šæœ‰æœŸå¾’åˆ‘{data.get('æœ‰æœŸå¾’åˆ‘', 0)}ä¸ªæœˆ"
    return result

def parser_documents(documents):
    """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„æ¡ˆä¾‹ï¼Œç”¨äº prompt"""
    result = ""
    for i, doc in enumerate(documents):
        text = doc.page_content + " åˆ¤å†³ç»“æœï¼š" + doc.metadata["result"] + "\n\n"
        result += f"æ¡ˆä¾‹{i}ï¼š{text}"
    return result

def merge_result(all_result):
    """åˆå¹¶å¤šæ¬¡æ¨ç†ç»“æœï¼šå¸ƒå°”å€¼å–æˆ–ï¼Œæ•°å€¼å–å¹³å‡"""
    death = any(r["æ˜¯å¦æ­»åˆ‘"] for r in all_result)
    life_imprisonment = any(r["æ˜¯å¦æ— æœŸ"] for r in all_result)
    
    months = [r["æœ‰æœŸå¾’åˆ‘"] for r in all_result if not r["æ˜¯å¦æ­»åˆ‘"] and not r["æ˜¯å¦æ— æœŸ"]]
    fines = [r["ç½šé‡‘"] for r in all_result]
    
    avg_month = int(sum(months) / len(months)) if months else 0
    avg_fine = int(sum(fines) / len(fines)) if fines else 0

    # è¿”å›ç¬¬ä¸€ä¸ªç»“æœå¹¶æ›´æ–°
    final = all_result[0].copy()
    final["æ˜¯å¦æ­»åˆ‘"] = death
    final["æ˜¯å¦æ— æœŸ"] = life_imprisonment
    final["æœ‰æœŸå¾’åˆ‘"] = avg_month
    final["ç½šé‡‘"] = avg_fine
    final["ç½ªå"] = list(set(acc for r in all_result for acc in r["ç½ªå"]))  # å»é‡åˆå¹¶ç½ªå
    return final

# ================== ä¸»é¢„æµ‹å‡½æ•° ==================
def predict(text, num=3):
    """
    è¾“å…¥æ¡ˆæƒ…ï¼Œè¾“å‡ºåˆ¤å†³ + ç›¸ä¼¼æ¡ˆä¾‹
    """
    print("ğŸ” æ­£åœ¨é¢„æµ‹ç½ªå...")
    predict_label = predict_accusation(text)
    print(f"âœ… é¢„æµ‹ç½ªå: {predict_label}")

    print("ğŸ” æ­£åœ¨æ£€ç´¢ç›¸ä¼¼æ¡ˆä¾‹...")
    similar_docs = db.similarity_search(
        text,
        k=10,
        filter={"category": predict_label}
    )[:3]

    print(similar_docs)
    
    if not similar_docs:
        print("âš ï¸ æœªæ‰¾åˆ°ç›¸ä¼¼æ¡ˆä¾‹ï¼Œä½¿ç”¨é€šç”¨æ¡ˆä¾‹...")
        similar_docs = db.similarity_search(text, k=3)

    case_list = parser_documents(similar_docs)

    print(f"ğŸ“Š åŸºäº {len(similar_docs)} ä¸ªç›¸ä¼¼æ¡ˆä¾‹è¿›è¡Œæ¨ç†...")
    all_result = []
    for i in tqdm(range(num), desc="ğŸ§  ç”Ÿæˆåˆ¤å†³æ¨ç†"):
        prompt = case_list + f"\nè¯·æ ¹æ®ä¸Šè¿°æ¡ˆä¾‹ï¼Œå¯¹ä»¥ä¸‹æ¡ˆä»¶åšå‡ºåˆ¤å†³ï¼š\n{text}\n{parser.get_format_instructions()}"
        try:
            response = llm_for_fix.invoke(prompt)
            result = fix_parser.parse(response.content)
            result["ç½ªå"] = [predict_label]
            all_result.append(result)
        except Exception as e:
            print(f"âŒ ç¬¬{i+1}æ¬¡æ¨ç†å¤±è´¥: {e}")
            continue

    if not all_result:
        raise Exception("æ‰€æœ‰æ¨ç†å‡å¤±è´¥")

    final_result = merge_result(all_result)
    return final_result, case_list

# ================== ä¸»ç¨‹åº ==================
if __name__ == "__main__":
    test_text = (
        "å…¬è¯‰æœºå…³èµ·è¯‰ä¹¦æŒ‡æ§å¹¶å®¡ç†ç»æŸ¥æ˜ï¼š2017å¹´8æœˆ24æ—¥10æ—¶è®¸ï¼Œè¢«å‘Šäººåˆ˜æŸåœ¨æœ¬å¸‚ä¸°å°åŒºæœ¨æ¨¨å›­é•¿é€”å®¢è¿ç«™å‡ºç«™é—¸æœºå¤„ "
        "ä¸é…åˆæ£€æŸ¥å·¥ä½œï¼Œç”¨éšèº«æºå¸¦çš„å°æ¨è½¦å†²æ’æ°‘è­¦ã€ç”¨é›¨ä¼å‡»æ‰“æ°‘è­¦å¤´éƒ¨ï¼Œåœ¨æ°‘è­¦åŠè¾…è­¦å¯¹å…¶è¿›è¡Œæ§åˆ¶æ—¶ï¼Œ"
        "å¯¹æ°‘è­¦åŠè¾…è­¦è¿›è¡Œè¾±éª‚ã€æŠ“æŒ ã€æ’•æ‰¯ï¼Œé€ æˆæ°‘è­¦å¼ 1æŸå³å‰è‡‚ã€åŒä¸‹è‚¢å¤šå¤„æŒ«ä¼¤ï¼Œè¾…è­¦é¾™æŸå³ä¸Šè‚¢çš®è‚¤æŒ«ä¼¤ã€‚"
        "ç»é‰´å®šï¼Œå¼ 1æŸã€é¾™æŸäºŒäººçš„æŸä¼¤ç¨‹åº¦å‡ä¸ºè½»å¾®ä¼¤ã€‚\n"
        "å…¬è¯‰æœºå…³å»ºè®®åˆ¤å¤„è¢«å‘Šäººåˆ˜æŸÃ—Ã—è‡³ä¸€å¹´ã€‚è¢«å‘Šäººåˆ˜æŸå¯¹æŒ‡æ§äº‹å®ã€ç½ªååŠé‡åˆ‘å»ºè®®æ²¡æœ‰å¼‚è®®ä¸”ç­¾å­—å…·ç»“ï¼Œ"
        "åœ¨å¼€åº­å®¡ç†è¿‡ç¨‹ä¸­äº¦æ— å¼‚è®®ã€‚"
    )

    print("ğŸš€ å¼€å§‹é¢„æµ‹...\n")
    result_json, case_list = predict(test_text, num=3)

    print("\n" + "="*50)
    print("ğŸ“Œ ç›¸ä¼¼æ¡ˆä¾‹ï¼š")
    print(case_list)

    result_str = accusation_json2str(result_json)
    print("\n" + "="*50)
    print("âš–ï¸  åˆ¤å†³ç»“æœï¼š")
    print(result_str)

    print("\n" + "="*50)
    print("ğŸ“œ ç”Ÿæˆå¸æ³•è§£é‡Š...")
    explanation_prompt = test_text + "\n" + result_str + "\n\nè¯·æ ¹æ®ä¸Šè¿°æ¡ˆæƒ…å’Œåˆ¤å†³ç»“æœï¼Œç»™å‡ºåˆç†çš„å¸æ³•è§£é‡Šã€‚"
    explanation = think(explanation_prompt, stream=False)
    print("å¸æ³•è§£é‡Šï¼š")
    print(explanation)
