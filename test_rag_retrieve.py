# test_retrieval.py
from langchain_community.vectorstores import FAISS
import os

from langchain_core.embeddings import Embeddings
from typing import List
from sentence_transformers import SentenceTransformer


class CustomEmbeddings(Embeddings):
    def __init__(self, model_name):
        self.model = SentenceTransformer(model_name)

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        return self.model.encode(texts, convert_to_numpy=True).tolist()

    def embed_query(self, text: str) -> List[float]:
        return self.model.encode([text], convert_to_numpy=True)[0].tolist()

def main():
    DB_DIR = "law_db"

    print("åŠ è½½åµŒå…¥æ¨¡å‹å’Œ FAISS æ•°æ®åº“...")
    embeddings = CustomEmbeddings('./Qwen3-Embedding-0.6B')
    
    # ä½¿ç”¨ allow_dangerous_deserialization=True æ˜¯å› ä¸ºä¿å­˜çš„æ˜¯è‡ªå®šä¹‰å¯¹è±¡
    # æ›´å®‰å…¨åšæ³•ï¼šä½¿ç”¨ `pickle` å¤–çš„åºåˆ—åŒ–æ–¹å¼ï¼ˆå¦‚ Chroma + HuggingFaceï¼‰
    db = FAISS.load_local(DB_DIR, embeddings, allow_dangerous_deserialization=True)

    query = "è¢«å‘Šäººéæ³•æ•çŒé‡ç”ŸåŠ¨ç‰©ï¼Œè¢«æŸ¥è·"
    print(f"\nğŸ” æŸ¥è¯¢: {query}\n")

    results = db.similarity_search(query, k=3)

    for i, r in enumerate(results, 1):
        print(f"--- åŒ¹é… {i} ---")
        print("æ¡ˆæƒ…:", r.page_content[:200] + ("..." if len(r.page_content) > 200 else ""))
        print("ç½ªå:", r.metadata["category"])
        print("åˆ¤å†³:", r.metadata["result"])
        print()


if __name__ == "__main__":
    main()
